[
  {
    "category": "Documentation",
    "description": "Update documentation on the Packages index",
    "steps": [
      "Using the code in ~/work/pulpcore as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory  the correct strategy for listing packages",
      "Using the code in  ~/work/pulp_python/ as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory documents the correct strategy for listing packages",
      "Using the code in  ~/work/pulp-docs/ as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory documents the correct strategy for listing packages",
      "Update ./PULP_DATA_MAPPING_PLAN.md if needed for accuracy"
    ],
    "passes": true
  },
  {
    "category": "Documentation",
    "description": "Update documentation on the Packages index search, filter, sorting and pagination",
    "steps": [
      "Using the code in ~/work/pulpcore as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory uses the correct strategy for searching, filtering, sorting and paginating packages",
      "Using the code in ~/work/pulp_python/ is refrence verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory uses the correct strategy for searching, filtering, sorting and paginating packages",
      "Using the code in  ~/work/pulp-docs/ as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory documents the correct strategy for listing packages",
      "Update ./PULP_DATA_MAPPING_PLAN.md if needed for accuracy"
    ],
    "passes": true
  },
  {
    "category": "Documentation",
    "description": "Update documentation on the Packages index",
    "steps": [
      "Using the code in ~/work/pulpcore as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory  the correct strategy for listing packages",
      "Using the code in  ~/work/pulp_python/ as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory documents the correct strategy for listing packages",
      "Using the code in  ~/work/pulp-docs/ as reference verify that the ./PULP_DATA_MAPPING_PLAN.md file in the current directory documents the correct strategy for listing packages",
      "Using all those references, look at the existing PULP_DATA_MAPPING_PLAN.md file and see if there are any more efficient ways to retrieve data from the pulp API",
      "Update ./PULP_DATA_MAPPING_PLAN.md as needed"
    ],
    "passes": true
  },
  {
    "category": "Functional",
    "description": "The service efficiently pulls all packages for the related distribution",
    "steps": [
      "The service pulls all packages for the selected distribution following the plan in ./PULP_DATA_MAPPING_PLAN.md",
      "Package data for the distribution are retrieved in a performant and best-practice manner"
    ],
    "passes": true
  },
  {
    "category": "Functional",
    "description": "Update the Packages index search",
    "steps": [
      "The service can search for packages following the plan in ./PULP_DATA_MAPPING_PLAN.md . Those packages are for a specific distribution"
    ],
    "passes": true
  },
  {
    "category": "Functional",
    "description": "Update the Package filtering",
    "steps": [
      "The service can filter packages following the plan in ./PULP_DATA_MAPPING_PLAN.md . Those packages are for a specific distribution"
    ],
    "passes": true
  },
  {
    "category": "Functional",
    "description": "Update the Package sorting",
    "steps": [
      "The service can sort packages following the plan in ./PULP_DATA_MAPPING_PLAN.md . Those packages are for a specific distribution"
    ],
    "passes": true
  },
  {
    "category": "Functional",
    "description": "Update the Package pagination",
    "steps": [
      "The service can paginate packages following the plan in ./PULP_DATA_MAPPING_PLAN.md . Those packages are for a specific distribution"
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Replace sequential full-fetch loop with progressive loading",
    "problem": "Currently in search-context.tsx:484-505, the code fetches ALL packages sequentially in a while loop. This causes: (1) Long initial loading time blocking the UI, (2) Sequential HTTP requests that can't be optimized, (3) Memory overhead from loading thousands of packages at once, (4) Poor user experience with infinite spinner",
    "rationale": "The current implementation was designed to work around Pulp API limitations (no server-side filtering for name substring, classifiers, license). However, fetching everything upfront is not scalable. We need a hybrid approach that balances server-side pagination with client-side filtering capabilities.",
    "steps": [
      "Implement progressive loading strategy: fetch first page (limit=100) immediately to show initial results",
      "Use the existing Pagination component's next-page button to trigger fetching the next page from the Pulp API on demand — no separate 'Load More' button or infinite scroll",
      "Update search-context.tsx to maintain a running dataset that grows as the user paginates, instead of fetching everything upfront",
      "Show initial results within 1-2 seconds, allow users to start browsing immediately",
      "Add loading indicators for incremental fetches (spinner or skeleton in the package list area, not full-page spinner)"
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Implement parallel page fetching for faster bulk loading",
    "problem": "The current while loop at search-context.tsx:484-505 fetches pages sequentially (page 1, wait, page 2, wait, etc.). This is inefficient when dealing with large datasets.",
    "rationale": "SUPERSEDED: The two-query approach using Pulp's Simple API (see 'Fix content-item pagination') eliminates the need to fetch all content items entirely. Instead of fetching thousands of items and deduplicating, we fetch unique names from the Simple API (1 request) and metadata for only the current page's packages (20 parallel requests). This is faster than any bulk-loading approach because it fetches only what's needed.",
    "steps": [
      "Replace sequential while loop with parallel Promise.all() approach",
      "First, make a single request to get total count",
      "Calculate total pages needed (Math.ceil(total / limit))",
      "Create array of fetch promises for all pages: const promises = Array.from({length: totalPages}, (_, i) => fetchPage(i))",
      "Execute in parallel with: const results = await Promise.all(promises)",
      "Limit concurrency to 5-10 requests at a time to avoid overwhelming the server",
      "Show progress indicator: 'Loading packages: 300/1000'"
    ],
    "passes": false
  },
  {
    "category": "UX",
    "description": "Add optimistic rendering with skeleton states",
    "problem": "Users see a spinner for potentially 10-30 seconds with no feedback on progress or partial results",
    "rationale": "Perceived performance is as important as actual performance. Show users something immediately and provide progress feedback.",
    "steps": [
      "Show skeleton cards immediately while first page loads",
      "Display actual results as soon as first page arrives (don't wait for all pages)",
      "Add progress indicator: 'Loaded 500 of ~2000 packages' during bulk fetch",
      "Update counts and pagination controls as more data arrives",
      "Allow users to interact with loaded results while remaining data fetches in background"
    ],
    "passes": false
  },
  {
    "category": "Architecture",
    "description": "Implement smart caching strategy with stale-while-revalidate",
    "problem": "Every distribution change triggers a full refetch of all packages, even if the data hasn't changed",
    "rationale": "Package data changes infrequently. We can show cached data immediately while fetching fresh data in the background.",
    "steps": [
      "Update useQuery configuration to use staleTime: 1000 * 60 * 30 (30 minutes instead of 5)",
      "Add cacheTime: 1000 * 60 * 60 (keep in cache for 1 hour)",
      "Use refetchOnMount: false to prevent unnecessary refetches",
      "Implement background refetch with refetchInterval: 1000 * 60 * 10 (10 minutes)",
      "Add manual refresh button for users who want latest data",
      "Show 'last updated' timestamp so users know data freshness"
    ],
    "passes": false
  },
  {
    "category": "Architecture",
    "description": "Add virtual scrolling for large package lists",
    "problem": "Rendering 1000+ package cards in the DOM causes performance issues (slow scrolling, high memory usage)",
    "rationale": "Virtual scrolling only renders visible items plus a small buffer, dramatically improving performance for large lists.",
    "steps": [
      "Install react-virtual or @tanstack/react-virtual library",
      "Replace Gallery component with virtual scroll container in search.tsx:380-570",
      "Configure virtual scrolling with estimated item height (e.g., 200px per card)",
      "Keep pagination for UX (users expect pages), but render current page with virtual scrolling",
      "This allows smooth scrolling even with 100+ items per page"
    ],
    "passes": false
  },
  {
    "category": "Feature",
    "description": "Implement server-side search enhancement via custom endpoint",
    "problem": "Pulp API lacks server-side filtering for name substring, classifiers, and license (verified in PULP_DATA_MAPPING_PLAN.md:10-19). This forces client-side filtering which requires fetching all data.",
    "rationale": "A custom API endpoint in the Express server can add missing filtering capabilities without modifying Pulp.",
    "steps": [
      "Add new endpoint in server/src/main.ts: GET /api/v2/packages/search",
      "Endpoint fetches from Pulp, then applies client-side filters server-side (better than browser)",
      "Support query params: ?q=<name_search>&classifier=<value>&license=<value>&limit=20&offset=0",
      "Server caches Pulp responses for 5 minutes to reduce repeated fetches",
      "Return paginated results matching UI expectations",
      "Update search-context.tsx to use this new endpoint instead of direct Pulp calls",
      "This moves filtering load from browser to server, enables true server-side pagination"
    ],
    "passes": false
  },
  {
    "category": "Performance",
    "description": "Implement request debouncing and cancellation",
    "problem": "User interactions (search typing, filter changes) can trigger multiple overlapping requests, wasting resources",
    "rationale": "Only the latest request matters. Cancel in-flight requests when new ones are triggered.",
    "steps": [
      "Already using useDeferredValue for search debouncing (good!)",
      "Add AbortController to cancel in-flight requests when parameters change",
      "Update useQuery to use enabled: !!selectedIndex && !!deferredSearchQuery to prevent empty searches",
      "Add 300ms debounce to filter changes before triggering new query",
      "Show 'Searching...' indicator during debounce period"
    ],
    "passes": false
  },
  {
    "category": "Monitoring",
    "description": "Add performance metrics and monitoring",
    "problem": "No visibility into how long packages take to load or how many packages are being fetched",
    "rationale": "Can't optimize what you don't measure. Need data to understand user experience and identify bottlenecks.",
    "steps": [
      "Add performance timing: const start = performance.now() before fetch, log duration after",
      "Track metrics: total packages fetched, time to first result, time to complete, number of HTTP requests",
      "Add console logging in dev mode: 'Fetched 1000 packages in 12.3s (8 requests)'",
      "Consider adding user-facing metrics: 'Searching 2,847 packages...' or 'Loaded 1000 packages'",
      "Log slow queries (>5s) for investigation"
    ],
    "passes": false
  },
  {
    "category": "Quick Win",
    "description": "Increase initial page size and add smarter pagination",
    "problem": "Current implementation fetches 100 items per page. For client-side filtering, this is too small and causes many requests.",
    "rationale": "Fetching larger chunks reduces number of HTTP requests while maintaining reasonable response times.",
    "steps": [
      "Change limit from 100 to 500 in search-context.tsx:474",
      "Reduce total pages fetched by 5x immediately",
      "Add smart pagination: if total < 1000, fetch all; if total > 1000, use progressive loading",
      "Update loading message to show: 'Loading packages (this may take a moment for large repositories)'",
      "This is a one-line change that can reduce load time by 50%"
    ],
    "passes": false
  },
  {
    "category": "UX",
    "description": "Add search result limits and warnings",
    "problem": "No feedback to users about dataset size or limits. Users don't know if they're searching 100 or 10,000 packages.",
    "rationale": "Transparency about data size helps users understand performance and set expectations.",
    "steps": [
      "Show total package count in header: 'Searching 2,847 packages from distribution X'",
      "Add warning if dataset is large: '⚠ This repository contains 5,000+ packages. Initial load may take 10-15 seconds.'",
      "Suggest using search/filters to narrow results: 'Tip: Use search or filters for faster results'",
      "Consider adding limit: only fetch first 2000 packages, show 'Showing first 2000 of 5000 packages'",
      "Add 'Show all' button to fetch remaining if user needs it"
    ],
    "passes": false
  },
  {
    "category": "Bug",
    "description": "Remove sortBy from useQuery queryKey to prevent refetching and inconsistent results across sort options",
    "problem": "In search-context.tsx:470, the queryKey is `[\"packages\", selectedIndex, sortBy]`. Including sortBy means each sort option (relevance, date, downloads) maintains a SEPARATE React Query cache entry. Changing sort invalidates the cache and triggers a full re-fetch with a different server-side ordering via mapSortToPulp() (lines 431-446): relevance maps to `ordering: name` (alphabetical), date/downloads map to `ordering: -pulp_created` (newest first). Since the Pulp content API returns ALL VERSIONS of ALL packages, different orderings produce pages with different content. If a fetch is interrupted, times out, or the dataset changes between sort-triggered re-fetches, completely different packages appear in each sort view. Meanwhile, all three sort strategies are ALREADY applied client-side at line 566 via applySorting() after deduplication, making the server-side sort entirely redundant.",
    "rationale": "The server-side sort via mapSortToPulp is unnecessary because the while loop fetches ALL data anyway — ordering on the server only affects page order, not final results. By removing sortBy from the queryKey, raw data is fetched once and cached regardless of sort option. The client-side applySorting() (lines 153-234) already correctly handles all three sort strategies (date, downloads, relevance scoring) on the deduplicated dataset. This eliminates redundant fetches and ensures consistent package lists across sort changes.",
    "steps": [
      "Change queryKey at search-context.tsx:470 from `[\"packages\", selectedIndex, sortBy]` to `[\"packages\", selectedIndex]`",
      "Remove the sort parameter from hubParams at search-context.tsx:487: delete `sort: mapSortToPulp(sortBy)` since server-side ordering is no longer needed",
      "Keep the client-side applySorting() call at line 566 unchanged — it already handles all three sort strategies correctly after deduplication",
      "Remove or deprecate the mapSortToPulp function (lines 431-446) and the buildPulpFilters function (lines 405-428) since neither produces server-side parameters",
      "Verify that changing sort options no longer triggers network requests or shows a loading spinner — sort changes should be instant client-side operations"
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Preserve Pulp API total count and compute correct totalItemCount vs filteredItemCount for pagination",
    "problem": "In search-context.tsx:572-583, both totalItemCount and filteredItemCount are set to `filteredPackages.length` — the count of packages AFTER fetching, deduplication, AND client-side filtering. The Pulp API's total count (PulpPaginatedResponse.count, representing total content items in the repository) is available in each API response but is discarded after the while loop at lines 484-505. The loop only accumulates `result.data` (the items array) and ignores `result.total`. As a result, the Pagination component (search.tsx:580) shows `itemCount={filteredItemCount}` which only reflects the client-side filtered array length, not the true repository size. Users see a count like '50' when the repository contains thousands of packages. The Inventory card (search.tsx:258-269) also shows an empty string because it has no access to the package count.",
    "rationale": "The Pulp API already provides the total count in every paginated response (PulpPaginatedResponse.count at models.ts:84). This value should be preserved through the data pipeline. The UI needs three distinct counts: (1) serverTotal — total content items from the API (useful for the Inventory card), (2) totalItemCount — unique packages after deduplication but before filtering (useful for showing 'X of Y packages'), (3) filteredItemCount — packages after client-side filtering (used for pagination page calculation). Currently all three are collapsed into filteredPackages.length.",
    "steps": [
      "In the useQuery queryFn (search-context.tsx:471-511), capture the total count from the API response: change `return allPackages` at line 507 to `return { packages: allPackages, serverTotal: allPackages.length > 0 ? result.total : 0 }` where result.total is preserved from the last loop iteration",
      "Declare a variable before the while loop to track the server total: `let serverTotal = 0;` and update it each iteration: `serverTotal = result.total;`",
      "Update the rawData destructuring at line 465 to extract both: `const { data: rawData, isLoading, error } = useQuery({ ... })` where rawData is now `{ packages, serverTotal }`",
      "Update transformedPackages memo (line 514) to use `rawData?.packages` instead of `rawData`",
      "In the pagination memo (lines 572-583), set totalItemCount to `transformedPackages.length` (unique packages post-dedup, pre-filter) and filteredItemCount to `filteredPackages.length` (post-filter). Expose serverTotal via context for the Inventory card",
      "Add serverTotal to the ISearchContext interface and provide it in all three SearchContext.Provider value objects (loading, error, success states)"
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Replace blocking while-loop with immediate first-page render and background data completion",
    "problem": "In search-context.tsx:484-505, the useQuery queryFn contains a `while (hasMore)` loop that fetches ALL packages (100 per request) sequentially before the query promise resolves. For a repository with 2000 packages across 5000+ content items (multiple versions per package), this means 50+ sequential HTTP requests chained together. During this entire multi-request sequence, React Query's isLoading remains true (line 466-467), and the UI renders a full-page Spinner with 'Loading packages...' text (search.tsx:335-353). Users see zero content until the very last page is fetched — potentially tens of seconds of blank loading screen. The while loop blocks at: `hasMore = result.data.length === limit && currentOffset < result.total` (line 504), continuing until every single page has been accumulated into the allPackages array.",
    "rationale": "SUPERSEDED: This approach was implemented but introduced a critical regression. The Pulp content API returns content items (individual files/versions), not unique packages. A single package can have hundreds of content items (e.g., scipy in calunga-dev has 2422 content items across 39 versions x 62 platform files). Fetching 20 content items per page returns 20 files of the SAME package, which deduplication reduces to 1 card — despite pagination claiming '1-20 of 2422'. The per-page approach fundamentally cannot work with Pulp's content model because deduplication must happen across ALL content items, not per-page. See 'Fix content-item pagination showing only 1 package per page' for the correct fix.",
    "steps": [
      "Replace the while-loop useQuery with a single page-at-a-time useQuery whose queryKey includes the current page and perPage: `queryKey: ['packages', selectedIndex, page, perPage]`",
      "Map the Pagination component's page/perPage state directly to Pulp API offset/limit parameters: `offset = (page - 1) * perPage`, `limit = perPage`",
      "The useQuery queryFn fetches exactly one page per call — no loop, no accumulation. It returns `{ packages: pageItems, serverTotal: count }` from a single HTTP request",
      "Render results immediately after each single-page fetch — users see content after one API round-trip instead of waiting for all pages",
      "When the user clicks the Pagination next-page button, page state updates, queryKey changes, and React Query fetches the next page from the Pulp API automatically",
      "Use the Pulp API's `count` field as the Pagination `itemCount` so users see the true total and can navigate to any page",
      "Apply deduplication and transformation only to the current page's results (not an accumulated global dataset)",
      "Leverage React Query's caching so previously visited pages are served from cache without re-fetching"
    ],
    "passes": false
  },
  {
    "category": "Bug",
    "description": "Fix invalid Pulp filter operator mapping causing 400 errors on package detail page",
    "problem": "Clicking a package from the search index navigates to the package detail page, which fetches package data via GET /pulp/api/v3/content/python/packages/?limit=1&offset=0&name__exact=<name>&version__exact=<version>. This returns a 400 Bad Request with the error 'Invalid Filter: name__exact, Invalid Filter: version__exact'. The root cause is in rest.ts:110-122 where mapHubOperatorToPulpOperator maps the '=' operator to '__exact'. This Pulp API instance does not support Django-style '__exact' lookup suffixes — it expects plain field names for exact matching (e.g., name=xxhash instead of name__exact=xxhash). The package detail context at package-detail-context-simple.tsx:48-52 constructs filters with operator '=' for both name and version, which get serialized as name__exact and version__exact by serializeRequestParamsForPulp (rest.ts:132-167). The same bug also affects package-detail.tsx:65-76 which fetches all versions using a name filter with operator '='. The search page (search-context.tsx) is unaffected because it uses filters: [] (empty array) and does all filtering client-side.",
    "rationale": "In Django REST Framework, using just the plain field name (e.g., ?name=value) defaults to exact matching, making the __exact suffix redundant. This Pulp instance explicitly rejects __exact as an invalid filter lookup. Changing the '=' operator mapping from '__exact' to '' (empty string) will produce plain field names (?name=value) which work correctly for exact matching. This is the most minimal and correct fix since it aligns with how the Pulp API actually validates filter parameters. Verified by testing: GET /pulp/api/v3/content/python/packages/?name=xxhash&version=3.6.0 returns 200 OK with correct results, while the __exact variant returns 400.",
    "steps": [
      "In rest.ts:110-122, change the '=' operator mapping in mapHubOperatorToPulpOperator from '__exact' to '' (empty string). This makes operator '=' produce plain field names (e.g., name=value) instead of name__exact=value",
      "Update the fallback return at rest.ts:121 from '__exact' to '' to match the new default behavior",
      "Verify that package-detail-context-simple.tsx:48-57 works without changes — the filters with operator '=' will now correctly serialize to name=<value>&version=<value>",
      "Verify that the all-versions query in package-detail.tsx:65-76 also works — its name filter with operator '=' will correctly serialize to name=<value>",
      "Test that the search page (search-context.tsx) is unaffected since it uses empty filters",
      "Test that other filter operators (~, ~~, !=, etc.) still serialize correctly with their Django lookup suffixes (__icontains, __contains, __exclude, etc.)"
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Fix packages not rendering after navigating back from package detail page",
    "problem": "In search-context.tsx:452-477, the useQuery queryFn stores fetched package data exclusively via React setState side effects (setAccumulatedPackages, setPulpServerTotal, setPulpPagesFetched) rather than consuming the query's returned data property. When a user clicks 'Back to Packages' on the package detail page (package-detail.tsx:220, navigate('/search')), the Search component and SearchProvider re-mount from scratch. All useState hooks reinitialize to their defaults: accumulatedPackages=[], pulpServerTotal=0, pulpPagesFetched=0. However, React Query finds the cached data for queryKey ['packages', selectedIndex, 'initial'] is still fresh (within the 5-minute staleTime at line 476), so queryFn is NOT re-executed and the setState side effects never run. The accumulatedPackages state stays [], producing empty transformedPackages, empty filteredPackages, and empty currentPageItems. The user sees 'No packages found' despite the data being available in React Query's cache.",
    "rationale": "The useQuery hook already returns the fetched data via its data property, but the component ignores it and relies solely on side effects in queryFn to populate separate React state. This is a known React Query anti-pattern: side effects in queryFn are not replayed when data is served from cache. The fix should either (a) initialize accumulatedPackages from the query's data property (e.g., via a useEffect that syncs query data into state on mount), or (b) restructure to use the query's data directly for the initial page and only use accumulatedPackages state for additional pages fetched via fetchNextPulpPage. Option (b) is preferred as it eliminates the state duplication entirely for the initial load.",
    "steps": [
      "In search-context.tsx, destructure the data property from the initial useQuery: change `const { isLoading, error } = useQuery(...)` to `const { data: initialData, isLoading, error } = useQuery(...)`",
      "Add a useEffect that syncs the query's cached data into accumulatedPackages state whenever initialData changes or is available from cache on mount: `useEffect(() => { if (initialData) { setAccumulatedPackages(initialData.packages); setPulpServerTotal(initialData.serverTotal); setPulpPagesFetched(1); } }, [initialData])`",
      "This ensures that when the component re-mounts and React Query serves cached data (without re-running queryFn), the accumulatedPackages state is still populated from the cache",
      "Verify that navigating to a package detail and clicking 'Back to Packages' now correctly renders the package list",
      "Verify that the initial load (first visit) still works correctly since queryFn sets state AND the useEffect also sets state from the returned data"
    ],
    "passes": true
  },
  {
    "category": "Architecture",
    "description": "Create mock data recording script to capture live Pulp API responses",
    "problem": "The app needs to run in demo mode on GitHub Pages without a Pulp backend, but currently all data comes from live Pulp API calls. Existing dummy-data.json files (client/src/pages/search/dummy-data.json, client/src/pages/python-wheels/dummy-data.json) are in the UI Package format, not the PulpPythonPackageContent format that the transformation pipeline (pulp-transformers.ts), deduplication (version-compare.ts), and filtering logic (search-context.tsx) all expect. Mock data must be in the Pulp API response format (PulpPaginatedResponse<PulpPythonPackageContent> and PulpPaginatedResponse<PulpDistribution>) so the entire downstream pipeline — transform, dedup, filter, sort, paginate — works identically in both modes.",
    "rationale": "Recording real API responses ensures the mock data is structurally accurate and includes realistic field values, classifiers, dependency lists, and version hierarchies. This avoids subtle bugs from hand-crafted mock data that might miss required fields or have unrealistic data shapes. The recording script runs once against the live Pulp instance (using the credentials in .env), captures the responses, and writes them to static JSON fixture files.",
    "steps": [
      "Create scripts/record-mock-data.ts — a Node.js script that uses the PULP_API_URL, PULP_USERNAME, and PULP_PASSWORD from the root .env file to authenticate against the live Pulp API",
      "The script fetches GET /api/v3/distributions/python/pypi/?limit=100 and saves the full PulpPaginatedResponse<PulpDistribution> to client/src/app/api/mock/data/distributions.json",
      "For each distribution, the script fetches GET /api/v3/content/python/packages/?repository_version=<repo_version>&limit=100 (first 100 packages) and saves the PulpPaginatedResponse<PulpPythonPackageContent> to client/src/app/api/mock/data/packages-<distribution-name>.json. Fetch up to 5 pages (500 packages) per distribution to have enough data for realistic pagination and filtering",
      "The script nullifies the 'next' and 'previous' URLs in the saved responses (replace with null) since mock mode won't follow pagination URLs — the mock API layer handles pagination client-side from the full dataset",
      "The script strips any sensitive data or internal URLs from pulp_href fields, replacing them with synthetic hrefs like /pulp/api/v3/content/python/packages/<uuid>/",
      "Add a package.json script: \"mock:record\": \"npx tsx scripts/record-mock-data.ts\" so it can be run easily. Document that this only needs to be run when you want to refresh the mock data",
      "After recording, verify the JSON files parse correctly and contain the expected PulpPythonPackageContent fields: name, version, summary, description, author, license, classifiers, filename, packagetype, python_version, requires_dist, requires_python, sha256, size, pulp_created, pulp_last_updated"
    ],
    "passes": true
  },
  {
    "category": "Architecture",
    "description": "Create mock API layer that intercepts Pulp API calls when MOCK=on",
    "problem": "The app currently makes live HTTP requests to the Pulp API via 4 functions in rest.ts: getAllDistributions(), getPulpPaginatedResult(), getDistributionForContent(), and getDistributionByBasePath(). On GitHub Pages there is no proxy server to forward these requests, so they fail. The app needs a mock API layer that provides the same function signatures and return types but serves data from static JSON fixture files bundled into the client build.",
    "rationale": "Intercepting at the API function level (rather than using MSW or network-level mocking) is the simplest approach: no extra dependencies, no service worker registration, no CORS concerns. The mock functions import the recorded JSON fixtures and implement client-side filtering, sorting, and pagination to simulate Pulp's behavior. The existing MOCK env var in CalungaEnvType (common/src/environment.ts:17, default 'off') controls the toggle. Since Vite's EJS plugin bakes window._env at build time for GitHub Pages builds (vite.config.ts:75-78), setting MOCK=on during the build makes it permanent in the static output.",
    "steps": [
      "Create client/src/app/api/mock/ directory structure: mock/data/ for JSON fixtures, mock/mock-api.ts for mock function implementations, mock/index.ts as the barrel export",
      "Create client/src/app/api/mock/mock-api.ts with mock implementations of the 4 Pulp API functions. Each function signature and return type must exactly match the real functions in rest.ts. Specifically: (1) getAllDistributions() returns Promise<PulpDistribution[]> — reads from distributions.json fixture; (2) getPulpPaginatedResult<T>(url, params, extraParams) returns Promise<HubPaginatedResult<T>> — reads from the appropriate packages JSON fixture based on the extraParams.repository_version, then applies client-side filtering using the same operator logic as serializeRequestParamsForPulp (field lookups for =, ~, !=, etc.), then sorts using the params.sort ordering, then paginates using params.page offset/limit, and returns { data: pageSlice, total: filteredTotal, params }; (3) getDistributionForContent(contentHref) returns Promise<PulpDistribution | null> — scans distributions fixture for one whose repository matches the content href prefix; (4) getDistributionByBasePath(basePath) returns Promise<PulpDistribution | null> — finds distribution by base_path in the fixture",
      "The mock getPulpPaginatedResult must support the same URL-based routing as the real API. Check the url parameter against PULP_ENDPOINTS values (PYTHON_CONTENT, PYTHON_DISTRIBUTIONS, etc.) to select the correct fixture file. This ensures search-context.tsx, package-detail-context-simple.tsx, and package-detail.tsx all work without changes",
      "Add a small simulated delay (50-200ms via setTimeout/Promise) to mock functions so the loading states and spinners render naturally in the UI, matching the real experience",
      "Wrap all mock data imports with dynamic import() or top-level await to avoid bundling the JSON fixtures when MOCK=off. Use: const data = await import('./data/distributions.json') pattern. This ensures the ~500KB of mock JSON does not bloat the production (live mode) bundle"
    ],
    "passes": true
  },
  {
    "category": "Architecture",
    "description": "Wire up MOCK env var to conditionally swap real and mock API implementations",
    "problem": "The mock API functions (from the previous task) exist but nothing routes to them. All consumers (search-context.tsx, package-detail-context-simple.tsx, package-detail.tsx, search.tsx) import directly from @app/api/rest.ts. We need a switching mechanism that routes these imports to mock implementations when MOCK=on, without changing any consumer code.",
    "rationale": "The cleanest approach is to create a barrel module (client/src/app/api/pulp.ts) that conditionally re-exports from either rest.ts or mock/mock-api.ts based on ENV.MOCK. All consumers then import from @app/api/pulp instead of @app/api/rest for Pulp-specific functions. This keeps rest.ts unchanged (it still has the real implementations), keeps mock-api.ts isolated, and the switch happens in one place. The ENV.MOCK value is available at runtime via window._env (decoded in client/src/app/env.ts:3).",
    "steps": [
      "Create client/src/app/api/pulp.ts as the new barrel module for all Pulp API functions. It imports ENV from @app/env and conditionally exports: if ENV.MOCK is 'on', export mock implementations from ./mock/mock-api; otherwise re-export the real implementations from ./rest. The exports are: getAllDistributions, getPulpPaginatedResult, getDistributionForContent, getDistributionByBasePath, and the PULP_ENDPOINTS constant (always from rest.ts since endpoints are just string constants used as keys)",
      "Update client/src/pages/search/search-context.tsx to import { getPulpPaginatedResult, PULP_ENDPOINTS } from '@app/api/pulp' instead of from '@app/api/rest'",
      "Update client/src/pages/search/search.tsx to import { getAllDistributions } from '@app/api/pulp' instead of from '@app/api/rest'",
      "Update client/src/pages/search/package-detail-context-simple.tsx to import { getPulpPaginatedResult, PULP_ENDPOINTS } from '@app/api/pulp' instead of from '@app/api/rest'",
      "Update client/src/pages/search/package-detail.tsx to import { getPulpPaginatedResult, PULP_ENDPOINTS } from '@app/api/pulp' instead of from '@app/api/rest'",
      "Verify that in live mode (MOCK=off, the default), the app behaves identically to before — all imports resolve to the real rest.ts functions",
      "Verify that in mock mode (MOCK=on), the app loads mock data from JSON fixtures with no network requests to /pulp/*"
    ],
    "passes": true
  },
  {
    "category": "DevOps",
    "description": "Update GitHub Pages build to enable mock mode and verify demo deployment",
    "problem": "The GitHub Actions workflow (.github/workflows/deploy.yml:37) currently builds with NODE_ENV=development BASE_URL=/calunga-ui-demo/ but does not set MOCK=on. The resulting static site deployed to GitHub Pages makes XHR requests to /pulp/api/v3/* which fail with network errors since there is no proxy server. The GitHub Pages demo shows a loading spinner forever or 'No packages found'.",
    "rationale": "Setting MOCK=on during the GitHub Pages build causes the Vite EJS plugin (vite.config.ts:75-78) to encode MOCK=on into window._env in the built HTML. When the static site loads in the browser, ENV.MOCK evaluates to 'on', the barrel module (pulp.ts) routes to mock implementations, and the app renders using the bundled JSON fixture data. No backend or proxy needed.",
    "steps": [
      "Update .github/workflows/deploy.yml line 37: change 'NODE_ENV=development BASE_URL=/calunga-ui-demo/ npm run build' to 'NODE_ENV=development BASE_URL=/calunga-ui-demo/ MOCK=on npm run build'. This single env var addition is the only deployment change needed",
      "Verify locally that the mock mode build works: run 'NODE_ENV=development BASE_URL=/ MOCK=on npm run build -w common && NODE_ENV=development BASE_URL=/ MOCK=on npm run build -w client', then serve client/dist/ with a static file server (e.g., npx serve client/dist) and confirm the app loads with mock data, package cards render, clicking a package shows the detail page, and navigating back works",
      "Verify that the live mode build is unaffected: run 'npm run build' without MOCK=on and confirm the production build does not include the mock JSON fixtures in the bundle (check bundle size or inspect the output)",
      "After pushing the workflow change to main, verify the GitHub Pages deployment at the repo's GitHub Pages URL shows a functional demo with mock package data"
    ],
    "passes": true
  },
  {
    "category": "Architecture",
    "description": "Add visual indicator for demo/mock mode in the UI",
    "problem": "When users visit the GitHub Pages demo, there is no indication that they are viewing mock data. They might think the app is connected to a real Pulp instance and be confused when data doesn't change or when features like uploads don't work.",
    "rationale": "A small, non-intrusive banner or badge in the masthead indicating 'Demo Mode' sets correct expectations. This also helps developers during local testing know which mode is active.",
    "steps": [
      "In client/src/app/layout/header.tsx (or wherever the masthead/header is defined), check ENV.MOCK === 'on' and conditionally render a PatternFly Label or Badge component with text 'Demo Mode' in the header area, styled with a distinctive color (e.g., gold/warning) so it's noticeable but not alarming",
      "The indicator should include a tooltip explaining: 'This is a demo running with sample data. No live Pulp server is connected.'",
      "When MOCK is 'off' (live mode), the indicator should not render at all — no empty space, no hidden element",
      "Ensure the indicator works in both dark and light PatternFly themes and doesn't break the header layout on narrow screens"
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Fix 'Search for packages...' filter returning incorrect results because search query is only applied client-side to the current page",
    "problem": "In search-context.tsx:428-451, the useQuery fetches a single page of content items from the Pulp API with queryKey ['packages', selectedIndex, page, perPage]. The search query (deferredSearchQuery) is NOT included in the queryKey and NOT sent to the API — hubParams at lines 435-438 has filters: [] (empty array). Consequently, typing in the 'Search for packages...' input never triggers a new API request. The client-side filter at lines 476-483 then runs against transformedPackages, which contains only the current page's worth of items (e.g., 20 content items that dedup to ~5-15 unique packages). Packages matching the search query that exist on other server pages are completely invisible. For example, searching for 'scipy' on a repository with 2422 packages checks only the ~15 packages on the current page — if scipy is not on page 1, the user sees 'No packages found'. Additionally, at lines 514-515, both totalItemCount and filteredItemCount are hardcoded to serverTotal (the unfiltered Pulp API count), so pagination shows '1 - 20 of 2422' even when the client-side filter has removed all items from the current page.",
    "rationale": "INCORRECT ASSUMPTION: This entry assumed the Pulp Python content API supports name__icontains filtering. Verified in pulp_python/app/viewsets.py:332-348 that PythonPackageContentFilter only supports 'name': ['exact', 'in'] — NOT 'icontains'. Sending name__icontains would return a 400 Bad Request. Since the Pulp API cannot do server-side substring search on package names, search must remain client-side. This is only fixable by fetching ALL content items first (see 'Fix content-item pagination showing only 1 package per page'), deduplicating, then applying client-side name/description filtering on the full deduplicated dataset. The per-page approach cannot support search because it only has access to one page of content items at a time.",
    "steps": [
      "This approach is INVALID — name__icontains is not a supported Pulp Python filter. The only supported name filters are name (exact match) and name__in (multiple exact matches).",
      "Search must remain client-side. FIXED: The two-query approach (see 'Fix content-item pagination') fetches ALL unique package names via getSimplePackageNames (Simple API or content API fallback). Client-side name search in search-context.tsx now operates on the complete name list, so search has full coverage regardless of pagination.",
      "The filteredAndSortedNames memo applies search query filtering on the full name list. Pagination slices the filtered list. totalItemCount shows total unique packages, filteredItemCount shows matches after search."
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Fix content-item pagination showing only 1 package per page when a distribution has packages with many versions",
    "problem": "When using the calunga-dev distribution, the search page shows only 1 package card (scipy) despite pagination reading '1 - 20 of 2422' and Inventory showing '2422 Packages'. Root cause: the Pulp content API (GET /pulp/api/v3/content/python/packages/) returns content items — each individual file (wheel, sdist) for each version of each package is a separate content item. A single package like scipy has 2422 content items (39 versions x ~62 platform-specific wheel/sdist files). The current code in search-context.tsx:428-450 fetches one page of 20 content items via `getPulpPaginatedResult` with `{ page: { pageNumber: page, itemsPerPage: perPage } }`. For calunga-dev, ALL 20 returned content items are scipy files (different versions/platforms). The deduplicateByLatestVersion() call at line 457 collapses these 20 scipy items into 1 unique package. The pagination component uses `serverTotal` (2422 — the raw content item count from the API), creating a massive mismatch: 1 card shown, but pagination says 2422 items across 122 pages. Clicking 'next page' shows the same 1 scipy card every time. Additionally, the Inventory card (search.tsx:266) shows '2422 Packages' which is misleading — it's 2422 content items, not unique packages. Verified by examining the mock data: packages-calunga-dev.json contains 500 results, ALL of which are scipy (the only unique package name).",
    "rationale": "The Pulp content API has no concept of 'unique packages' — it only knows about content items (files). Fetching all content items to deduplicate client-side is not scalable (minutes for large distributions). However, Pulp's PyPI Simple API (GET /pypi/{base_path}/simple/) uses database-level DISTINCT to return unique package names in a single lightweight request. Combined with per-page metadata fetching (content API with name={exact}&limit=1 for each name on the current page), this gives instant page loads regardless of distribution size. The two-query approach: (1) Simple API for all names (cached), (2) content API for current page's metadata (N parallel requests).",
    "steps": [
      "REVISED: Use Pulp's PyPI Simple API via a dedicated /pypi proxy. The PyPI Simple API (GET /pypi/{basePath}/simple/) lives at a different path (/api/pypi/...) than the Pulp REST API (/api/pulp/...), so it cannot be reached through the existing /pulp proxy. Add a /pypi proxy route in both vite.config.ts and server/src/proxies.js that targets PYPI_API_URL (defaults to PULP_API_URL with /pulp/ replaced by /pypi/). The /pypi proxy must NOT override the Accept header (unlike /pulp) so PEP 691 application/vnd.pypi.simple.v1+json gets through. Add PYPI_API_URL to common/src/environment.ts (CalungaEnvType + SERVER_ENV_KEYS + buildCalungaEnv). In rest.ts, getSimplePackageNames(basePath) calls GET /pypi/{basePath}/simple/ with Accept: application/vnd.pypi.simple.v1+json. Returns unique package names via database-level DISTINCT — a single lightweight request. Supports PEP 691 JSON and PEP 503 HTML response formats. No fallback to content API fetching (that approach is too slow for large distributions). Add mock implementation in mock-api.ts. Wire through pulp.ts barrel module.",
      "In search-context.tsx, replace the single all-content-items query with two queries: Query 1 (queryKey: ['packageNames', selectedIndex]) fetches all unique names via getSimplePackageNames — one lightweight request, cached 5 minutes. Query 2 (queryKey: ['packageDetails', basePath, currentPageNames]) fetches metadata for only the current page's packages — N parallel requests via Promise.all, each calling getPulpPaginatedResult with name={exact}&ordering=-pulp_created&limit=1 to get the latest content item per package.",
      "Client-side name search operates on the full name list (all names loaded from Simple API), so search has full coverage. Pagination slices the filtered/sorted name list. Sort by relevance scores names by search query match quality. Alphabetical sort is the default.",
      "Set totalItemCount to the total unique package count (from Simple API). Set filteredItemCount to the count after name search. The Inventory card shows the true unique package count.",
      "Limitation: Classification and license filters require per-package metadata, which is only loaded for the current page. These filters apply to the current page's packages only. Full-coverage classification/license filtering would require a server-side search endpoint (see 'Implement server-side search enhancement' entry).",
      "React Query caching: names are cached 5 min (staleTime). Per-page metadata is cached per page of names. Navigating between pages fetches only that page's metadata. Previously visited pages served from cache."
    ],
    "passes": true
  },
  {
    "category": "Bug",
    "description": "Fix license text overflow rendering full license agreement in package card",
    "problem": "In the search page package cards, the license metadata renders the full license text without truncation. For packages like scipy, the `license` field from the Pulp API contains the complete BSD license agreement — 55,247 characters of legal text. In pulp-transformers.ts:41, the transformer copies this verbatim: `license: content.license || content.license_expression || 'Unknown'`. In search.tsx:501-503, the card footer renders `{pkg.license}` directly. This causes a massive wall of text in the card footer, making the card unusable and pushing other package cards far below the viewport. The same issue affects any package where the upstream setup.py/pyproject.toml embeds the full license text rather than a short identifier like 'BSD' or 'MIT'.",
    "rationale": "The `license` field in Python package metadata is a free-text field — some packages use short identifiers (e.g., 'MIT', 'Apache-2.0') while others embed the entire license agreement. The PEP 639 `license_expression` field (SPDX format) is the newer standard for short identifiers, but many packages only populate the legacy `license` field. The fix should truncate the license text for card display and prefer `license_expression` (SPDX) when available since it's always a short identifier.",
    "steps": [
      "In pulp-transformers.ts:41, change the license assignment to prefer license_expression (SPDX, always short) over license (free-text, potentially very long): `license: content.license_expression || (content.license?.length > 100 ? content.license.substring(0, 100) + '...' : content.license) || 'Unknown'`",
      "Alternatively, truncate in the card rendering at search.tsx:501-503: add CSS `overflow: hidden; text-overflow: ellipsis; white-space: nowrap; max-width: 200px` to the license FlexItem, or truncate the text with JavaScript: `{pkg.license.length > 80 ? pkg.license.substring(0, 80) + '...' : pkg.license}`",
      "For the package detail page (package-detail.tsx), show the full license text since there's room — only truncate in the search card view",
      "Test with the scipy mock data (license field is 55,247 chars) to verify the card renders at a reasonable height"
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Use Pulp `fields` parameter on search page Query 2 to reduce metadata payload by ~60%",
    "problem": "In search-context.tsx:410-437, Query 2 fetches full PulpPythonPackageContent objects for each package on the current page. Each full object contains ~25+ fields, many of which are never used on the search page. The `description` field alone can be 55KB+ (e.g., scipy's full package description), `requires_dist` arrays contain 50+ entries, and fields like `sha256`, `size`, `home_page`, `project_urls`, `author_email`, `requires_python`, and `keywords` are fetched but never consumed by `transformPulpContentToPackage()` in pulp-transformers.ts:17-68. For a page of 20 packages, this means potentially megabytes of unused data transferred over the network. Verified in pulpcore/app/serializers/base.py:431 that pulpcore's ModelSerializer inherits QueryFieldsMixin from `drf-queryfields`, which supports a `fields` query parameter to select specific response fields. This is a standard DRF feature, not a custom extension.",
    "rationale": "The `fields` query parameter is supported by all Pulp content API endpoints via the QueryFieldsMixin in pulpcore's base ModelSerializer. Adding `fields=pulp_href,name,version,summary,author,maintainer,license,license_expression,pulp_created,filename,python_version,classifiers` to each metadata request eliminates all unused fields from the response. This reduces per-item payload from ~2-5KB to ~300-500 bytes — a 60-80% reduction with zero functional impact since the transformer only reads the listed fields. The `description` field (which can be 55KB for packages like scipy) is NOT needed on search cards — the transformer uses `summary` for the card description and `description` only for `fullDescription`, which is not displayed on the search page.",
    "steps": [
      "In search-context.tsx:410-437 (Query 2 queryFn), add a `fields` parameter to the extraParams passed to getPulpPaginatedResult. Change the extraParams from `{ ...extraParams, name, ordering: '-pulp_created', limit: 1 }` to `{ ...extraParams, name, ordering: '-pulp_created', limit: 1, fields: 'pulp_href,name,version,summary,author,maintainer,license,license_expression,pulp_created,filename,python_version,classifiers' }`. This tells the Pulp API to only serialize and return the listed fields.",
      "Verify that transformPulpContentToPackage in pulp-transformers.ts:17-68 still works correctly with the reduced field set — all fields it reads (pulp_href, name, version, summary, pulp_created, author, maintainer, license, license_expression, classifiers, filename, python_version) are included in the fields list. The `description` field is intentionally excluded since it's only used for fullDescription which is not needed on the search page.",
      "Update the mock API in mock-api.ts to handle the `fields` parameter if present — filter the response objects to only include the requested fields. This ensures mock mode behaves identically to live mode.",
      "Test that search page cards render correctly with the reduced payload — name, version, description (from summary), author, license, tags, and date should all display normally.",
      "Measure the payload reduction in browser DevTools Network tab: compare response sizes before and after the change for a page of 20 packages."
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Replace N parallel metadata requests with single `name__in` batch query on search page",
    "problem": "In search-context.tsx:410-437, Query 2 makes N parallel HTTP requests (typically 20, one per package on the current page) via Promise.all. Each request calls `getPulpPaginatedResult(PULP_ENDPOINTS.PYTHON_CONTENT, { filters: [] }, { name, ordering: '-pulp_created', limit: 1 })`, resulting in 20 separate HTTP round-trips to the Pulp API. On the server, each request triggers a separate PostgreSQL query. While HTTP/2 multiplexing mitigates some connection overhead, 20 requests still generate 20 separate DB queries and 20 response/parse cycles. Verified in pulp_python/app/viewsets.py:332-348 that PythonPackageContentFilter supports `name: ['exact', 'in']` — meaning `?name__in=pkg1,pkg2,...,pkg20` is a valid batch filter that translates to a single PostgreSQL `WHERE name IN (...)` query.",
    "rationale": "Replacing 20 individual `?name=X&limit=1` requests with a single `?name__in=X,Y,Z,...&ordering=-pulp_created` request reduces HTTP round-trips from 20 to 1 and DB queries from 20 to 1. The trade-off: the batch request returns ALL content items (all versions/platforms) for those 20 package names, not just the latest 1 per name. For distributions with many versions per package, this could return hundreds of items. However, combined with the `fields` parameter (previous entry), each item is ~300-500 bytes, making even 500 items only ~150-250KB — acceptable for a single request. Client-side deduplication (keep first occurrence per name, since results are ordered by -pulp_created) extracts the latest version per package. The `name__in` filter uses PostgreSQL's efficient index-based IN lookup, which is faster than 20 sequential index scans.",
    "steps": [
      "In search-context.tsx:410-437, replace the Promise.all loop that makes N parallel requests with a single batch request. Change the queryFn to: (1) join currentPageNames with commas, (2) call getPulpPaginatedResult with extraParams `{ ...extraParams, name__in: currentPageNames.join(','), ordering: '-pulp_created', fields: 'pulp_href,name,version,summary,author,maintainer,license,license_expression,pulp_created,filename,python_version,classifiers' }`, (3) client-side deduplicate the results by keeping the first occurrence of each name (latest version due to ordering).",
      "Set the `limit` parameter high enough to ensure all 20 package names have at least one content item in the response. Use `limit: 2000` as a safe upper bound. The `getPulpPaginatedResult` function's `fetchAllPages` recursive helper will follow `next` URLs if needed, but with only 20 package names this is rarely necessary.",
      "Implement client-side deduplication after the batch fetch: iterate through results in order, using a Set to track seen names, and keep only the first content item per name. This preserves the latest version per package since results are ordered by `-pulp_created`.",
      "Handle the edge case where a package name has no content items in the batch response (e.g., if it was deleted between Query 1 and Query 2). Filter out missing names from the final result.",
      "Update the mock API to support the `name__in` filter parameter — split the comma-separated value and filter fixtures where `item.name` is in the list.",
      "Test with distributions that have uneven version counts (e.g., calunga-dev where scipy has 2422 items). Verify all 20 package names appear in the results even when one package dominates the content item count."
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Use Pulp `fields` parameter on package detail page queries to reduce payload",
    "problem": "The package detail page makes two content API calls, both fetching full PulpPythonPackageContent objects: (1) In package-detail-context-simple.tsx:48-62, Query 1 fetches a specific package by name+version — the full object is needed here for the detail view, but fields like requires_dist, sha256, size, keywords are still unused. (2) In package-detail.tsx:60-84, Query 2 fetches ALL versions of a package with `itemsPerPage: 100` to check for newer stable versions. This query only uses `version` and `pulp_created` from each result (lines 78-80 transform to Package, but only `version` is used in the hasNewerVersion check at lines 87-139). Fetching 100 full objects when only 2 fields are needed wastes significant bandwidth — especially for packages with large description or requires_dist fields.",
    "rationale": "Query 2 in package-detail.tsx:60-84 is the bigger optimization target. It fetches up to 100 full PulpPythonPackageContent objects but the hasNewerVersion logic (lines 87-139) only reads `pkg.version` from each result. Adding `fields=name,version,pulp_created,pulp_href` to this query reduces per-item payload from ~2-5KB to ~100 bytes — a 95% reduction for what could be 100 items. For Query 1 (the specific version), the full object is more justified since the detail page displays many fields, but `exclude_fields=requires_dist,sha256,size,keywords,home_page,project_urls` could still reduce payload significantly without affecting the UI.",
    "steps": [
      "In package-detail.tsx:60-84, add fields restriction to the all-versions query. Change the getPulpPaginatedResult call to include a third extraParams argument: `{ fields: 'pulp_href,name,version,pulp_created' }`. These are the only fields needed by the hasNewerVersion check. The transformPulpContentToPackage call at line 78-80 will produce Package objects with empty/default values for unused fields, which is fine since only `version` is read.",
      "In package-detail-context-simple.tsx:48-62, optionally add `exclude_fields=requires_dist` to reduce payload for the specific version query. The requires_dist field is an array of 50+ dependency strings that is never displayed in the current UI. This is a smaller optimization but still meaningful for packages with many dependencies.",
      "Test that the 'Newer version available' badge in package-detail.tsx:249-263 still appears correctly when a newer stable version exists.",
      "Test that the package detail Overview, Versions, Files, and Security tabs all render correctly with the reduced field set."
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Use PyPI JSON Metadata API for package detail to eliminate N+1 query pattern",
    "problem": "The package detail page makes 2 sequential content API calls: (1) package-detail-context-simple.tsx:48-62 fetches the specific version by name+version, (2) package-detail.tsx:60-84 fetches all versions of the same package (enabled only after Query 1 completes via `enabled: !!packageData`). This is a classic N+1 pattern — 2 HTTP round-trips that could be 1. The PyPI JSON Metadata API endpoint at GET /pypi/{basePath}/pypi/{packageName}/json/ (pulp_python/app/pypi/views.py:439-467) returns all the data both queries need in a single response: full package metadata (info section with name, version, summary, author, license, classifiers, etc.) plus all versions with release files (releases section). This endpoint already exists and is served through the /pypi proxy.",
    "rationale": "The PyPI JSON Metadata API is specifically designed for this use case — displaying full package details with version history. It returns the same data structure as PyPI's public JSON API (e.g., https://pypi.org/pypi/requests/json/), making it a standard interface. Using it eliminates the N+1 pattern, reduces HTTP round-trips from 2 to 1, and provides richer data (including download URLs and file digests) that could be useful for the Files tab. The response format is well-documented (PEP 566) and includes pre-computed fields like `releases` (all versions grouped by version string) that eliminate the need for client-side version deduplication.",
    "steps": [
      "Add a new function in rest.ts: `getPackageMetadata(basePath: string, packageName: string, version?: string)` that calls GET /pypi/{basePath}/pypi/{packageName}/json/ (or GET /pypi/{basePath}/pypi/{packageName}/{version}/json/ for a specific version). Parse the response according to the PyPI JSON API format: `{ info: { name, version, summary, author, license, classifiers, ... }, releases: { '1.0.0': [...files], '2.0.0': [...files] }, urls: [...current_version_files] }`.",
      "Add the function to the pulp.ts barrel module and create a corresponding mock implementation in mock-api.ts that constructs the PyPI JSON response format from the existing fixture data.",
      "Update package-detail-context-simple.tsx to use `getPackageMetadata` instead of `getPulpPaginatedResult`. Map the `info` section to the Package model and the `releases` section to PackageVersion[]. This replaces Query 1.",
      "Update package-detail.tsx to consume the versions from the Package model returned by the context (which now includes all versions from the PyPI JSON response) instead of making a separate Query 2. Remove or simplify the second useQuery call.",
      "Test that the package detail page loads with a single network request instead of two. Verify that the 'Newer version available' badge, Versions tab, and Files tab all work correctly with data from the PyPI JSON API."
    ],
    "passes": true
  },
  {
    "category": "Performance",
    "description": "Prefetch adjacent page metadata for instant pagination",
    "problem": "When the user clicks 'Next Page' in the search results, Query 2 fetches metadata for the new page's packages. This causes a visible loading delay (spinner or opacity change) on every page change because the batch name__in request and deduplication must complete before results render. Users browsing through pages experience a jarring delay on each navigation.",
    "rationale": "React Query's queryClient.prefetchQuery() allows background data fetching without triggering UI loading states. By prefetching the next (and optionally previous) page's metadata while the user views the current page, pagination becomes near-instant for sequential browsing — the most common navigation pattern. The prefetched data sits in React Query's cache and is served immediately when the user navigates. The cost is minimal: one extra background HTTP request per page view, amortized by the high likelihood the user will navigate to the adjacent page. The prefetch uses the same queryKey structure as Query 2 (['packageDetails', basePath, pageNames]), so it integrates seamlessly with existing cache invalidation.",
    "steps": [
      "Import useQueryClient from @tanstack/react-query in search-context.tsx",
      "After Query 2 completes successfully, compute the next page's package names: nextPageNames = filteredAndSortedNames.slice(startIndex + perPage, startIndex + 2 * perPage)",
      "Use a useEffect that runs when currentPageItems changes (i.e., after Query 2 resolves) to call queryClient.prefetchQuery with queryKey ['packageDetails', basePath, nextPageNames] and the same queryFn as Query 2 but with nextPageNames instead of currentPageNames",
      "Optionally prefetch the previous page as well for backward navigation",
      "Ensure prefetch does NOT run when nextPageNames is empty (last page) or when the component is unmounting",
      "Test that clicking 'Next Page' renders results instantly (from cache) without any loading indicator"
    ],
    "passes": false
  },
  {
    "category": "Performance",
    "description": "Increase cache duration for package names from 5 to 30 minutes",
    "problem": "In search-context.tsx:345, the package names query (Query 1 via getSimplePackageNames) uses staleTime: 1000 * 60 * 5 (5 minutes). Package names in a Pulp distribution change very infrequently — typically only when a new package is published or removed, which might happen a few times per day at most. With a 5-minute staleTime, switching between distributions or navigating back to the search page after 5 minutes triggers a full refetch of the names list. Since the Simple API returns ALL unique names for the distribution, this is a lightweight request (~10-50KB), but the refetch still causes a loading state flash and delays rendering.",
    "rationale": "Package names are highly cacheable data. Increasing staleTime to 30 minutes reduces unnecessary refetches by 6x. Combined with React Query's gcTime (garbage collection time, default 5 minutes after last subscriber unmounts), cached names persist across navigation within a session. For real-time freshness, a manual refresh button (already suggested in the 'smart caching strategy' PRD entry) allows users to force-fetch when needed. The 30-minute window is a conservative choice — PyPI itself caches the Simple API index for hours.",
    "steps": [
      "In search-context.tsx:345, change staleTime from 1000 * 60 * 5 to 1000 * 60 * 30",
      "Also increase gcTime (formerly cacheTime) to 1000 * 60 * 60 (1 hour) to keep names in cache longer after the search page unmounts, so returning to search is instant",
      "Apply the same staleTime increase to the distributions query in search.tsx:619 (currently 10 minutes, increase to 30 minutes) since distributions change even less frequently than package names",
      "Verify that switching distributions still triggers a fresh names fetch (the queryKey includes selectedIndex, so different distributions have separate cache entries)",
      "Verify that navigating to package detail and back renders the search page instantly from cache without a loading spinner"
    ],
    "passes": false
  },
  {
    "category": "Performance",
    "description": "Use PyPI Root API for instant inventory counts before names finish loading",
    "problem": "The Inventory card on the search page (search.tsx:258-269) displays totalItemCount, which is derived from packageNames.length — meaning the count is only available AFTER the full names list finishes loading from the Simple API (Query 1). During loading, the Inventory card shows '0 Packages'. For distributions with thousands of packages, the Simple API response can take 1-3 seconds, during which the user sees no inventory information. Pulp's PyPI Root API (GET /pypi/{basePath}/) returns pre-computed aggregate counts {projects, releases, files} using database-level DISTINCT — a much faster query than fetching the full name list.",
    "rationale": "The PyPI Root API (pulp_python/app/pypi/views.py:485-492) executes three DB-level COUNT DISTINCT queries which are significantly faster than the Simple API's full name list retrieval. Fetching this endpoint in parallel with Query 1 provides instant inventory numbers. The 'projects' count from the Root API is the exact same value as packageNames.length (both use DISTINCT on name), but it arrives faster because the response is tiny ({projects: N, releases: N, files: N}) compared to the full name list. This also provides bonus data: release count and file count, which could enhance the Inventory card with richer statistics.",
    "steps": [
      "Add a new function in rest.ts: getDistributionStats(basePath: string) that calls GET /pypi/{basePath}/ and returns { projects: number, releases: number, files: number }",
      "Add the function to pulp.ts barrel module and create a mock implementation in mock-api.ts that computes counts from fixture data",
      "In search-context.tsx, add a new useQuery with queryKey ['distributionStats', basePath] that calls getDistributionStats. Run it in parallel with Query 1 (package names). Set staleTime: 1000 * 60 * 30",
      "Expose distributionStats via the SearchContext so the Inventory card can display project/release/file counts immediately, even before the full names list loads",
      "Update the Inventory card in search.tsx to show distributionStats.projects as the primary count, falling back to totalItemCount (from names list) once loaded. Optionally show releases and files counts as secondary metrics",
      "Test that the Inventory card shows a count within 200-500ms of page load, before the full names list arrives"
    ],
    "passes": false
  }
]
